# SEFI
<img src="https://github.com/NeoSunJZ/Canary_Master/blob/main/logo.png?raw=true" width="200" alt="">

[![standard-readme compliant](https://img.shields.io/badge/readme%20style-standard-brightgreen.svg?style=flat-square)](https://github.com/RichardLitt/standard-readme)

## Introduction

SEFI is a framework for evaluating the robustness of artificial intelligence. It will generate adversarial samples based on selected models using selected attack methods and use these adversarial samples to attack any model you wish. In the process it will collect data including adversarial sample quality, model result deflection and model baseline inference as a basis for evaluating the robustness of AI models and the effectiveness of attack methods, while finding the best defense solution.

It additionally provides a toolkit with multiple models, SOTA attack methods and defense methods, and allows users to integrate more on their own.

SEFI is created and maintained by researchers at Beijing Institute of Technology.

## User's Manual

We are actively preparing the user manual and will be publicly available soon.

## Maintainers

[@NeoSunJz](https://github.com/NeoSunJz).

## Contributing

### Contributors

This project exists thanks to all the people who contribute.

## License

[Apache 2.0](LICENSE) Â© Beijing Institute of Technology
